---
layout: post
title: "EmoTrack: The Graduate Individual Project"
date: 2024-05-09
categories: [Project, Research]
tags: [Flutter, Firebase, HCI, Python]
---


<!-- ![Project Banner](https://你的图片链接.png)  -->

### Overview
This project is the culmination of my MEng dissertation at the **University of Bristol**. **EmoTrack** is a research-driven Personal Informatics application designed to help users track their YouTube viewing habits and reflect on their emotional responses.

> [View the Full Source Code and Description on GitHub](https://github.com/ruiyongzhang/emotrack)

> [View the User Instruction](https://www.notion.so/EmoTrack-User-Instructions-2bd2a6e1683c45efa0fd9676fa91eaca)

> [View the Demo Video on YouTube](https://youtu.be/fgxkX1vDObI)

### The Challenge
Online engagement is complex. Distinguishing between beneficial and harmful content is difficult for algorithms, so I took an alternative approach: **helping users develop the skills to manage their own online safety.**

### How it Works
1. **Data Import:** Users upload their YouTube history via Google Takeout.
2. **Analysis:** The system categorizes videos using OpenAI's GPT models.
3. **Reflection:** Users view their dashboard and log how they felt about specific viewing sessions.

### Tech Stack
- **Mobile/Web:** Flutter
- **Backend:** Firebase (Auth, Firestore)
- **AI/Data:** Python, OpenAI API

### Academic Results
The system was evaluated with 13 participants. The findings showed that EmoTrack effectively facilitated self-reflection, helping users identify "time-wasting" content and pivot towards more positive digital engagement.

---
<!-- *For more details, you can check out my [Full Dissertation PDF](./assets/Thesis_1958793_Final.pdf) or explore the [Readme](https://github.com/ruiyongzhang/app-project).* -->